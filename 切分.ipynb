{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8d110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "input_path = 'shanhaijing.txt'  # 源文本放在当前工作目录\n",
    "out_dir = 'shanhaijing'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "def safe_name(name: str) -> str:\n",
    "    # 去掉开头的*并清理成安全文件名\n",
    "    name = name.strip().lstrip('*').strip()\n",
    "    return re.sub(r'[\\\\/:*?\"<>|]+', '_', name) or 'chapter'\n",
    "\n",
    "def unique_txt_path(dir_, base):\n",
    "    path = os.path.join(dir_, f'{base}.txt')\n",
    "    i = 1\n",
    "    while os.path.exists(path):\n",
    "        i += 1\n",
    "        path = os.path.join(dir_, f'{base}_{i}.txt')\n",
    "    return path\n",
    "\n",
    "chap_title = None\n",
    "chap_lines = []\n",
    "\n",
    "with open(input_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.lstrip().startswith('*'):\n",
    "            # 写出上一章\n",
    "            if chap_title is not None:\n",
    "                base = safe_name(chap_title)\n",
    "                out_path = unique_txt_path(out_dir, base)\n",
    "                with open(out_path, 'w', encoding='utf-8') as w:\n",
    "                    w.write(chap_title.strip() + '\\n')\n",
    "                    w.writelines(chap_lines)\n",
    "            # 开始新章\n",
    "            chap_title = line.strip()\n",
    "            chap_lines = []\n",
    "        else:\n",
    "            chap_lines.append(line)\n",
    "\n",
    "# 写出最后一章\n",
    "if chap_title is not None:\n",
    "    base = safe_name(chap_title)\n",
    "    out_path = unique_txt_path(out_dir, base)\n",
    "    with open(out_path, 'w', encoding='utf-8') as w:\n",
    "        w.write(chap_title.strip() + '\\n')\n",
    "        w.writelines(chap_lines)\n",
    "\n",
    "print('完成：已按“*”分章并保存到 shanhaijing 文件夹')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb7ef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并完成：merged.csv，来源 46 个文件，合计 2709 行数据（仅一行表头）\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "folder = 'csv_by_category'\n",
    "out_file = 'merged.csv'\n",
    "\n",
    "# 递归查找所有子文件夹里的 CSV\n",
    "pattern = os.path.join(folder, '**', '*.csv')\n",
    "files = sorted(glob.glob(pattern, recursive=True))\n",
    "\n",
    "if not files:\n",
    "    print('无CSV文件')\n",
    "else:\n",
    "    dfs = [pd.read_csv(f) for f in files]\n",
    "    merged = pd.concat(dfs, ignore_index=True)\n",
    "    merged.to_csv(out_file, index=False, encoding='utf-8')\n",
    "    print(f'合并完成：{out_file}，来源 {len(files)} 个文件，合计 {len(merged)} 行数据（仅一行表头）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(\n",
    "    # 如果没有配置环境变量，请用API Key将下行替换为：api_key=\"sk-xxx\"\n",
    "    # 新加坡和北京地域的API Key不同。获取API Key：https://help.aliyun.com/zh/model-studio/get-api-key\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),\n",
    "    # 以下是北京地域base_url，如果使用新加坡地域的模型，需要将base_url替换为：https://dashscope-intl.aliyuncs.com/compatible-mode/v1\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n",
    ")\n",
    "name='天虞'\n",
    "category='人名'\n",
    "description='有人反臂'\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-max\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"你是《山海经》研究专家和AI图像生成提示词专家。请基于形象,分类和描述生成适合AI绘画的prompt，如果有描述，详细扩写描述部分内容，不要有其他内容，如果没有则自由发挥，利用你的知识库搜索相关的神话学、考古学资料，参考古代插画风格和传统中国美学的彩色水墨风格,只返回prompt，以prompt开头。\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"名字：{name}，分类：{category}，描述：{description}\", \n",
    "        },\n",
    "    ],\n",
    "    extra_body={\"enable_search\": True}\n",
    ")\n",
    "\n",
    "json_string = completion.choices[0].message.content\n",
    "print(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5153c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存: 中山經.txt\n",
      "已保存: 中次二經.txt\n",
      "已保存: 中次三經.txt\n",
      "已保存: 中次四經.txt\n",
      "已保存: 中次五經.txt\n",
      "已保存: 中次六經.txt\n",
      "已保存: 中次七經.txt\n",
      "已保存: 中次八經.txt\n",
      "已保存: 中次九經.txt\n",
      "已保存: 中次十經.txt\n",
      "已保存: 中次一十一山經.txt\n",
      "已保存: 中次十二經.txt\n",
      "已保存: 五臧山經.txt\n",
      "已保存: 北山經.txt\n",
      "已保存: 北山經.txt\n",
      "已保存: 北次二經.txt\n",
      "已保存: 北次三經.txt\n",
      "已保存: 北次三經.txt\n",
      "已保存: 南次二經.txt\n",
      "已保存: 南次二經.txt\n",
      "已保存: 南次三經.txt\n",
      "已保存: 南次三經.txt\n",
      "已保存: 東山經.txt\n",
      "已保存: 東山經.txt\n",
      "已保存: 東次二經.txt\n",
      "已保存: 東次二經.txt\n",
      "已保存: 東次三經.txt\n",
      "已保存: 東次三經.txt\n",
      "已保存: 東次四經.txt\n",
      "已保存: 東次四經.txt\n",
      "已保存: 西山經.txt\n",
      "已保存: 西經.txt\n",
      "已保存: 西次二經.txt\n",
      "已保存: 西次二經.txt\n",
      "已保存: 西次三經.txt\n",
      "已保存: 西次三經.txt\n",
      "已保存: 西次四經.txt\n",
      "已保存: 西次四經.txt\n",
      "\n",
      "处理完成！\n"
     ]
    }
   ],
   "source": [
    "#細切\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 源文件夹和目标文件夹\n",
    "source_folder = r\"d:\\study\\研一上\\CHC5904\\demo\\shanhaijing copy\"\n",
    "output_folder = r\"d:\\study\\研一上\\CHC5904\\demo\\shanhaijing_split\"\n",
    "\n",
    "# 创建输出文件夹\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 遍历所有txt文件\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.endswith('.txt'):\n",
    "        filepath = os.path.join(source_folder, filename)\n",
    "        \n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # 使用正则表达式找到所有《》标记的经书\n",
    "        sections = re.split(r'《([^》]+)》', content)\n",
    "        \n",
    "        # sections[0]是第一个《》之前的内容，通常是标题\n",
    "        # sections[1], sections[3], sections[5]... 是经书名称\n",
    "        # sections[2], sections[4], sections[6]... 是对应的内容\n",
    "        \n",
    "        for i in range(1, len(sections), 2):\n",
    "            if i + 1 < len(sections):\n",
    "                section_name = sections[i].strip()\n",
    "                section_content = sections[i + 1].strip()\n",
    "                \n",
    "                if section_content:  # 只保存非空内容\n",
    "                    output_filename = f\"{section_name}.txt\"\n",
    "                    output_path = os.path.join(output_folder, output_filename)\n",
    "                    \n",
    "                    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(f\"《{section_name}》\\n\\n{section_content}\")\n",
    "                    \n",
    "                    print(f\"已保存: {output_filename}\")\n",
    "\n",
    "print(\"\\n处理完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
